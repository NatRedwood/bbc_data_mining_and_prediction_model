# BBC News Data Mining and Text Classification with Predcition Model
This project is a part of the individual tutoring program in Varsity Tutors.

## Project Description
The purpose of this project is:
1. Extracting important features of BBC News using NLTK tools like: stemming, tokenizing, removing stopwords.
2. Analyzing BBC News corpus: frequency distribution, most correlated unigrams, tfidf.
3. Building a prediction model to classify the genre of a BBC News example text. 

### Methods Used
* Text Mining
* Machine Learning
* Data Visualization
* Predictive Modeling
* Chi-Squared Distribution
* TSNE
* Logistic Regression
* RandomForestClassifier
* MultinomialNB
* Cross Validation

### Technologies
* Python, jupyter
* NLTK Tools: stemming, tokenizing
* Pandas, scikit-learn, TfidfVectorizer
* matplotlib, seaborn

## Needs of this project

- data exploration/descriptive statistics
- data processing/cleaning
- statistical modeling

## Get Started

1. Clone this repo: tutorial [link](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data: [link](https://github.com/Nwojarnik/bbc_data_mining_and_prediction_model/blob/main/bbc-text.csv) within this repo.
3. Data processing/transformation Python script: [link](https://github.com/Nwojarnik/bbc_data_mining_and_prediction_model/blob/main/bbc%20data.py)
 Jupyter Notebook file: [link](https://github.com/Nwojarnik/bbc_data_mining_and_prediction_model/blob/main/bbc%20data.ipynb)
